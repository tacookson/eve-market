---
title: "clean-orders"
author: "Alex Cookson"
date: "02/11/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load libraries

```{r}
library(tidyverse)
library(lubridate)
library(Hmisc)
library(janitor)
```

Create cleaning function

```{r}
clean_gz_file <- function(x) {
  as_tibble(x) %>%
    separate(value,
             into = c("datetime", "actual_trade", "sell_order", "order_id", "price", "units", "location_id"),
             sep = ",") %>%
    mutate(row_number = row_number(),
           meta_bin = is.na(actual_trade),
           meta_value = ifelse(is.na(actual_trade), datetime, NA),
           datetime = ifelse(is.na(meta_value), datetime, NA),
           region_id = ifelse(str_length(meta_value) > 7, "region_id", NA),
           trade_count = ifelse(lag(region_id) == "region_id", "trade_count", NA),
           region_count = ifelse(!is.na(lead(region_id)) & meta_bin, "region_count", NA),
           item_id = ifelse(!is.na(lead(region_id, 2)) & meta_bin, "item_id", NA),
           meta_key = coalesce(region_id, trade_count, region_count, item_id)) %>%
    select(-region_id:-item_id) %>%
    spread(meta_key, meta_value) %>%
    fill(item_id, region_id, .direction = "down") %>%
    filter(!meta_bin) %>%
    select(item_id, region_id, location_id, datetime:units) %>%
    mutate_at(vars(item_id:datetime, order_id:units), parse_number, na = "None") %>%
    mutate(datetime = as_datetime(datetime / 1000),
           actual_trade = str_detect(actual_trade, "T"),
           sell_order = str_detect(sell_order, "T"))
}
```

Import data from .gz files (currently need to define the path to a specific year-month folder)

```{r}
path <- "./data/raw-gz/201905/"
file_list <- paste0(path, list.files(path))

gz_files <- map(file_list, readLines) %>%
  unlist()
```

Clean data using cleaning function defined above

```{r}
market <- clean_gz_file(gz_files)

rm(gz_files)

market %>%
  write_csv("raw-201905.csv")
```

Summarise data by day (broken down by item, region, and order type)

```{r}
daily_summary <- market %>%
  mutate(date = as_date(datetime)) %>%
  filter(units > 0) %>%
  group_by(item_id, region_id, date, sell_order) %>%
  summarise(mean_price = wtd.mean(price, weights = units),
            median_price = wtd.quantile(price, weights = units, probs = 0.5),
            percentile_05 = wtd.quantile(price, weights = units, probs = 0.05),
            percentile_25 = wtd.quantile(price, weights = units, probs = 0.25),
            percentile_75 = wtd.quantile(price, weights = units, probs = 0.75),
            percentile_95 = wtd.quantile(price, weights = units, probs = 0.95),
            units_traded = sum(units)) %>%
  ungroup()

daily_summary %>% write_csv("daily-201905.csv")
```

### Post-cleaning testing steps

Import reference table for item_id and market types

```{r}
ids <- read_csv("./reference/invTypes.csv") %>%
  clean_names() %>%
  rename(item_id = type_id,
         item_name = type_name)
```

Join reference table to raw trade data

```{r}
market_joined <- market %>% left_join(ids, by = "item_id") %>%
  select(item_id, item_name,
         group_id, group_name,
         market_group_id, market_group_name,
         region_id, location_id, datetime, sell_order, price, units)

market_joined %>%
  mutate(value = price * units) %>%
  count(group_name, market_group_name, item_name, wt = value, sort = TRUE) %>%
  top_n(50) %>% View()
```

Test summarising to Jita (region_id == 10000002) Orca (item_id == 28606) trades

```{r}
market_joined %>%
  filter(region_id == 10000002,
         str_detect(item_name, "Gila"),
         price < 500000000) %>%
  mutate(order_type = as.factor(ifelse(!sell_order, "bought from sell order", "sold to buy order"))) %>%
  ggplot(aes(datetime, price, col = order_type)) +
  geom_point(alpha = 0.5) +
  scale_y_continuous(labels = scales::comma_format())
  geom_smooth()
```